<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="PyCon2023_files/libs/clipboard/clipboard.min.js"></script>
<script src="PyCon2023_files/libs/quarto-html/tabby.min.js"></script>
<script src="PyCon2023_files/libs/quarto-html/popper.min.js"></script>
<script src="PyCon2023_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="PyCon2023_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="PyCon2023_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="PyCon2023_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="PyCon2023_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.528">

  <meta name="author" content="Alonso Silva">
  <title>Poniéndose al día con el extraño mundo de los LLMs</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="PyCon2023_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="PyCon2023_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="PyCon2023_files/libs/revealjs/dist/theme/quarto.css">
  <link href="PyCon2023_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="PyCon2023_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="PyCon2023_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="PyCon2023_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Poniéndose al día con el extraño mundo de los LLMs</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Alonso Silva 
</div>
</div>
</div>

</section>
<section id="de-noviembre-de-2022" class="slide level2">
<h2>30 de noviembre de 2022</h2>
<div id="57779f69" class="cell" data-scrolled="true" data-execution_count="3">
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<figure>
<p><img data-src="PyCon2023_files/figure-revealjs/cell-3-output-1.jpeg"></p>
</figure>
</div>
</div>
</div>

<aside><div>
<p>Escena de la película “2001: Odisea del espacio” de Stanley Kubrick</p>
</div></aside></section>
<section id="yo-desde-esa-fecha" class="slide level2">
<h2>Yo desde esa fecha…</h2>

<img data-src="PyCon2023_files/figure-revealjs/cell-4-output-1.jpeg" class="r-stretch"></section>
<section id="agricultores-antes-del-motor-a-combustión-interna" class="slide level2">
<h2>Agricultores antes del motor a combustión interna</h2>

<img data-src="PyCon2023_files/figure-revealjs/cell-5-output-1.jpeg" class="r-stretch"></section>
<section id="agricultores-después-del-motor-a-combustión-interna" class="slide level2">
<h2>Agricultores después del motor a combustión interna</h2>

<img data-src="PyCon2023_files/figure-revealjs/cell-6-output-1.jpeg" class="r-stretch"></section>
<section id="quehaceres" class="slide level2">
<h2>Quehaceres</h2>
</section>
<section id="instalación" class="slide level2">
<h2>Instalación</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource console number-lines code-with-copy"><code class="sourceCode"><span id="cb1-1"><a href=""></a>pip install langchain==0.0.331</span>
<span id="cb1-2"><a href=""></a>pip install openai==0.28.1</span>
<span id="cb1-3"><a href=""></a>pip install pydantic==1.10.8</span>
<span id="cb1-4"><a href=""></a>pip install python-dotenv==1.0.0</span>
<span id="cb1-5"><a href=""></a>pip install wikipedia==1.4.0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="obtener-llave" class="slide level2">
<h2>Obtener llave</h2>
<p><a href="https://platform.openai.com/">https://platform.openai.com/</a></p>
<div class="sourceCode" id="cb2" data-code-line-numbers="1-6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="im">import</span> os</span>
<span id="cb2-2"><a href=""></a><span class="im">import</span> openai</span>
<span id="cb2-3"><a href=""></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv, find_dotenv</span>
<span id="cb2-4"><a href=""></a></span>
<span id="cb2-5"><a href=""></a>_ <span class="op">=</span> load_dotenv(find_dotenv()) <span class="co"># read local .env file</span></span>
<span id="cb2-6"><a href=""></a>openai.api_key <span class="op">=</span> os.environ[<span class="st">'OPENAI_API_KEY'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="tabla-de-contenidos" class="slide level2">
<h2>Tabla de contenidos</h2>
<p>Presente de los LLMs</p>
<div class="fragment semi-fade-out">
<p>Órganos internos de los LLMs</p>
<p>Conclusiones y perspectivas</p>
</div>
</section>
<section id="presente-de-los-llms" class="slide level2">
<h2>Presente de los LLMs</h2>
<p>Chatbots</p>
<div class="fragment semi-fade-out">
<p>Generación Aumentada con Recuperación (RAG)</p>
<p>Etiquetado</p>
<p>Extracción</p>
<p>Agentes</p>
</div>
</section>
<section id="chatbot" class="slide level2">
<h2>Chatbot</h2>
</section>
<section id="chatbot-1" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb3-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb3-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb3-4"><a href=""></a></span>
<span id="cb3-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb3-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb3-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb3-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb3-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb3-10"><a href=""></a>])</span>
<span id="cb3-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb3-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"¡Hola!"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chatbot-2" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb4" data-code-line-numbers="11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb4-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb4-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb4-4"><a href=""></a></span>
<span id="cb4-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb4-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb4-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb4-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb4-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb4-10"><a href=""></a>])</span>
<span id="cb4-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb4-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"¡Hola!"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chatbot-3" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb5" data-code-line-numbers="1,5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb5-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb5-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb5-4"><a href=""></a></span>
<span id="cb5-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb5-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb5-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb5-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb5-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb5-10"><a href=""></a>])</span>
<span id="cb5-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb5-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"¡Hola!"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chatbot-4" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb6" data-code-line-numbers="3,6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb6-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb6-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb6-4"><a href=""></a></span>
<span id="cb6-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb6-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb6-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb6-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb6-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb6-10"><a href=""></a>])</span>
<span id="cb6-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb6-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"¡Hola!"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chatbot-5" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb7" data-code-line-numbers="2,7-10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb7-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb7-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb7-4"><a href=""></a></span>
<span id="cb7-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb7-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb7-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb7-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb7-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb7-10"><a href=""></a>])</span>
<span id="cb7-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb7-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"¡Hola!"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chatbot-6" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb8" data-code-line-numbers="12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb8-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb8-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb8-4"><a href=""></a></span>
<span id="cb8-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb8-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb8-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb8-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb8-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb8-10"><a href=""></a>])</span>
<span id="cb8-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb8-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"¡Hola!"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chatbot-7" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb9-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb9-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb9-4"><a href=""></a></span>
<span id="cb9-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb9-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb9-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb9-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb9-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb9-10"><a href=""></a>])</span>
<span id="cb9-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb9-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"¡Hola!"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="46eb3a27-508c-403f-85ce-d84a4c42629e" class="cell" data-execution_count="99">
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>'¡Hola! ¿En qué puedo ayudarte hoy?'</code></pre>
</div>
</div>
</section>
<section id="chatbot-8" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb11" data-code-line-numbers="9,12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb11-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb11-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb11-4"><a href=""></a></span>
<span id="cb11-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb11-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb11-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb11-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb11-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb11-10"><a href=""></a>])</span>
<span id="cb11-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb11-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"Quién fue Isaac Newton?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chatbot-9" class="slide level2">
<h2>Chatbot</h2>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb12-2"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb12-3"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb12-4"><a href=""></a></span>
<span id="cb12-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb12-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb12-7"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb12-8"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil."</span>),</span>
<span id="cb12-9"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb12-10"><a href=""></a>])</span>
<span id="cb12-11"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb12-12"><a href=""></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"Quién fue Isaac Newton?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="242c2d59-6ad3-4da8-bdcb-88efd404bff9" class="cell" data-execution_count="40">
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>'Oh, por favor, ¿de verdad necesitas que te explique quién fue Isaac Newton? Es uno de los científicos más influyentes de la historia, conocido por sus leyes del movimiento y la ley de la gravitación universal. Sus descubrimientos sentaron las bases de la física moderna. Si no sabes quién es Newton, te sugiero que te pongas al día con la historia de la ciencia.'</code></pre>
</div>
</div>
</section>
<section id="bravucongpt" class="slide level2">
<h2>BravuconGPT</h2>
<p><a href="https://hf.co/spaces/alonsosilva/BravuconGPT">https://hf.co/spaces/alonsosilva/BravuconGPT</a></p>
<div id="32a3f590-162c-4021-8910-575be6d1e133" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display" data-execution_count="4">

        <iframe width="850" height="450" src="https://alonsosilva-bravucongpt.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="talkativeai" class="slide level2">
<h2>TalkativeAI</h2>
<p><a href="https://talkativeai.streamlit.app/">https://talkativeai.streamlit.app/</a></p>
<div id="5c378d2e-f7d7-45d7-9c9b-d7b3708df117" class="cell" data-execution_count="25">
<div class="cell-output cell-output-display" data-execution_count="25">

        <iframe width="850" height="550" src="https://talkativeai.streamlit.app/?embed=True" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="presente-de-los-llms-1" class="slide level2">
<h2>Presente de los LLMs</h2>
<p>Chatbots</p>
<p>Generación Aumentada con Recuperación (RAG)</p>
<div class="fragment semi-fade-out">
<p>Etiquetado</p>
<p>Extracción</p>
<p>Agentes</p>
</div>
</section>
<section id="generación-aumentada-con-recuperación-rag" class="slide level2">
<h2>Generación Aumentada con Recuperación (RAG)</h2>
</section>
<section id="rag" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href=""></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb14-2"><a href=""></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> DocArrayInMemorySearch</span>
<span id="cb14-3"><a href=""></a></span>
<span id="cb14-4"><a href=""></a>vectorstore <span class="op">=</span> DocArrayInMemorySearch.from_texts(</span>
<span id="cb14-5"><a href=""></a>    [<span class="st">"Felipe trabaja en Nokia"</span>, <span class="st">"A los osos les gusta comer miel"</span>],</span>
<span id="cb14-6"><a href=""></a>    embedding<span class="op">=</span>OpenAIEmbeddings()</span>
<span id="cb14-7"><a href=""></a>)</span>
<span id="cb14-8"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb14-9"><a href=""></a>retriever.get_relevant_documents(<span class="st">"¿Dónde trabaja Felipe?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-1" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb15" data-code-line-numbers="1,6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href=""></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb15-2"><a href=""></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> DocArrayInMemorySearch</span>
<span id="cb15-3"><a href=""></a></span>
<span id="cb15-4"><a href=""></a>vectorstore <span class="op">=</span> DocArrayInMemorySearch.from_texts(</span>
<span id="cb15-5"><a href=""></a>    [<span class="st">"Felipe trabaja en Nokia"</span>, <span class="st">"A los osos les gusta comer miel"</span>],</span>
<span id="cb15-6"><a href=""></a>    embedding<span class="op">=</span>OpenAIEmbeddings()</span>
<span id="cb15-7"><a href=""></a>)</span>
<span id="cb15-8"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb15-9"><a href=""></a>retriever.get_relevant_documents(<span class="st">"¿Dónde trabaja Felipe?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-2" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb16" data-code-line-numbers="2,4-7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href=""></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb16-2"><a href=""></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> DocArrayInMemorySearch</span>
<span id="cb16-3"><a href=""></a></span>
<span id="cb16-4"><a href=""></a>vectorstore <span class="op">=</span> DocArrayInMemorySearch.from_texts(</span>
<span id="cb16-5"><a href=""></a>    [<span class="st">"Felipe trabaja en Nokia"</span>, <span class="st">"A los osos les gusta comer miel"</span>],</span>
<span id="cb16-6"><a href=""></a>    embedding<span class="op">=</span>OpenAIEmbeddings()</span>
<span id="cb16-7"><a href=""></a>)</span>
<span id="cb16-8"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb16-9"><a href=""></a>retriever.get_relevant_documents(<span class="st">"¿Dónde trabaja Felipe?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-3" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb17" data-code-line-numbers="8-9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href=""></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb17-2"><a href=""></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> DocArrayInMemorySearch</span>
<span id="cb17-3"><a href=""></a></span>
<span id="cb17-4"><a href=""></a>vectorstore <span class="op">=</span> DocArrayInMemorySearch.from_texts(</span>
<span id="cb17-5"><a href=""></a>    [<span class="st">"Felipe trabaja en Nokia"</span>, <span class="st">"A los osos les gusta comer miel"</span>],</span>
<span id="cb17-6"><a href=""></a>    embedding<span class="op">=</span>OpenAIEmbeddings()</span>
<span id="cb17-7"><a href=""></a>)</span>
<span id="cb17-8"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb17-9"><a href=""></a>retriever.get_relevant_documents(<span class="st">"¿Dónde trabaja Felipe?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-4" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href=""></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb18-2"><a href=""></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> DocArrayInMemorySearch</span>
<span id="cb18-3"><a href=""></a></span>
<span id="cb18-4"><a href=""></a>vectorstore <span class="op">=</span> DocArrayInMemorySearch.from_texts(</span>
<span id="cb18-5"><a href=""></a>    [<span class="st">"Felipe trabaja en Nokia"</span>, <span class="st">"A los osos les gusta comer miel"</span>],</span>
<span id="cb18-6"><a href=""></a>    embedding<span class="op">=</span>OpenAIEmbeddings()</span>
<span id="cb18-7"><a href=""></a>)</span>
<span id="cb18-8"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb18-9"><a href=""></a>retriever.get_relevant_documents(<span class="st">"¿Dónde trabaja Felipe?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="ea821db4-67b5-465d-a75b-53040cc7508a" class="cell" data-execution_count="46">
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>[Document(page_content='Felipe trabaja en Nokia')]</code></pre>
</div>
</div>
</section>
<section id="rag-5" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb20" data-code-line-numbers="9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href=""></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb20-2"><a href=""></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> DocArrayInMemorySearch</span>
<span id="cb20-3"><a href=""></a></span>
<span id="cb20-4"><a href=""></a>vectorstore <span class="op">=</span> DocArrayInMemorySearch.from_texts(</span>
<span id="cb20-5"><a href=""></a>    [<span class="st">"Felipe trabaja en Nokia"</span>, <span class="st">"A los osos les gusta comer miel"</span>],</span>
<span id="cb20-6"><a href=""></a>    embedding<span class="op">=</span>OpenAIEmbeddings()</span>
<span id="cb20-7"><a href=""></a>)</span>
<span id="cb20-8"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb20-9"><a href=""></a>retriever.get_relevant_documents(<span class="st">"¿Qué comen los osos?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-6" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href=""></a><span class="im">from</span> langchain.embeddings <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb21-2"><a href=""></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> DocArrayInMemorySearch</span>
<span id="cb21-3"><a href=""></a></span>
<span id="cb21-4"><a href=""></a>vectorstore <span class="op">=</span> DocArrayInMemorySearch.from_texts(</span>
<span id="cb21-5"><a href=""></a>    [<span class="st">"Felipe trabaja en Nokia"</span>, <span class="st">"A los osos les gusta comer miel"</span>],</span>
<span id="cb21-6"><a href=""></a>    embedding<span class="op">=</span>OpenAIEmbeddings()</span>
<span id="cb21-7"><a href=""></a>)</span>
<span id="cb21-8"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever(search_kwargs<span class="op">=</span>{<span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb21-9"><a href=""></a>retriever.get_relevant_documents(<span class="st">"¿Qué comen los osos?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="e4984d99-839d-44e5-b58c-89c96ea71add" class="cell" data-execution_count="47">
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>[Document(page_content='A los osos les gusta comer miel')]</code></pre>
</div>
</div>
</section>
<section id="rag-7" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb23-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb23-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb23-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb23-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb23-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb23-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb23-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb23-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb23-10"><a href=""></a>})</span>
<span id="cb23-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb23-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb23-13"><a href=""></a></span>
<span id="cb23-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb23-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb23-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb23-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb23-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-8" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb24" data-code-line-numbers="17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb24-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb24-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb24-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb24-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb24-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb24-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb24-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb24-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb24-10"><a href=""></a>})</span>
<span id="cb24-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb24-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb24-13"><a href=""></a></span>
<span id="cb24-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb24-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb24-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb24-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb24-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-9" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb25" data-code-line-numbers="1,5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb25-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb25-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb25-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb25-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb25-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb25-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb25-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb25-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb25-10"><a href=""></a>})</span>
<span id="cb25-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb25-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb25-13"><a href=""></a></span>
<span id="cb25-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb25-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb25-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb25-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb25-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-10" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb26" data-code-line-numbers="2,6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb26-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb26-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb26-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb26-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb26-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb26-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb26-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb26-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb26-10"><a href=""></a>})</span>
<span id="cb26-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb26-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb26-13"><a href=""></a></span>
<span id="cb26-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb26-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb26-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb26-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb26-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-11" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb27" data-code-line-numbers="3,7-10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb27-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb27-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb27-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb27-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb27-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb27-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb27-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb27-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb27-10"><a href=""></a>})</span>
<span id="cb27-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb27-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb27-13"><a href=""></a></span>
<span id="cb27-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb27-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb27-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb27-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb27-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-12" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb28" data-code-line-numbers="11-16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb28-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb28-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb28-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb28-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb28-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb28-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb28-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb28-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb28-10"><a href=""></a>})</span>
<span id="cb28-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb28-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb28-13"><a href=""></a></span>
<span id="cb28-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb28-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb28-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb28-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb28-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-13" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb29" data-code-line-numbers="18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb29-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb29-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb29-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb29-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb29-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb29-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb29-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb29-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb29-10"><a href=""></a>})</span>
<span id="cb29-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb29-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb29-13"><a href=""></a></span>
<span id="cb29-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb29-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb29-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb29-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb29-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-14" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb30-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb30-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb30-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb30-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb30-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb30-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb30-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb30-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb30-10"><a href=""></a>})</span>
<span id="cb30-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb30-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb30-13"><a href=""></a></span>
<span id="cb30-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb30-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb30-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb30-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb30-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de Felipe?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="2bdef0f4-234d-4f2a-9092-d6e558e97513" class="cell" data-execution_count="58">
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>'Felipe trabaja en Nokia.'</code></pre>
</div>
</div>
</section>
<section id="rag-15" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb32" data-code-line-numbers="18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb32-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb32-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb32-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb32-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb32-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb32-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb32-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb32-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb32-10"><a href=""></a>})</span>
<span id="cb32-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb32-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb32-13"><a href=""></a></span>
<span id="cb32-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb32-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb32-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb32-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb32-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de osos?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rag-16" class="slide level2">
<h2>RAG</h2>
<div class="sourceCode" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb33-2"><a href=""></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb33-3"><a href=""></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnableMap</span>
<span id="cb33-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb33-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>)</span>
<span id="cb33-6"><a href=""></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb33-7"><a href=""></a>runnable_map <span class="op">=</span> RunnableMap({</span>
<span id="cb33-8"><a href=""></a>    <span class="st">"context"</span>: <span class="kw">lambda</span> x: retriever.get_relevant_documents(x[<span class="st">"question"</span>]),</span>
<span id="cb33-9"><a href=""></a>    <span class="st">"question"</span>: <span class="kw">lambda</span> x: x[<span class="st">"question"</span>]</span>
<span id="cb33-10"><a href=""></a>})</span>
<span id="cb33-11"><a href=""></a>template <span class="op">=</span> <span class="st">"""Answer the question based only on the following context:</span></span>
<span id="cb33-12"><a href=""></a><span class="sc">{context}</span></span>
<span id="cb33-13"><a href=""></a></span>
<span id="cb33-14"><a href=""></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb33-15"><a href=""></a><span class="st">"""</span></span>
<span id="cb33-16"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(template)</span>
<span id="cb33-17"><a href=""></a>chain <span class="op">=</span> runnable_map <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb33-18"><a href=""></a>chain.invoke({<span class="st">"question"</span>: <span class="st">"¿Qué sabes acerca de osos?"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="4fbee3cf-6efe-406e-a1e2-5afcd93d5788" class="cell" data-execution_count="60">
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>'De acuerdo con el contexto proporcionado, sabemos que a los osos les gusta comer miel.'</code></pre>
</div>
</div>
</section>
<section id="word2vec" class="slide level2">
<h2>Word2Vec</h2>
<p><a href="https://hf.co/spaces/alonsosilva/word2vec">https://hf.co/spaces/alonsosilva/word2vec</a></p>
<div id="78964dab-30f5-4a6c-8d01-c5cfd24deff0" class="cell" data-execution_count="29">
<div class="cell-output cell-output-display" data-execution_count="29">

        <iframe width="850" height="450" src="https://alonsosilva-word2vec.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="embeddings" class="slide level2">
<h2>Embeddings</h2>
<p><a href="https://hf.co/spaces/alonsosilva/embeddings">https://hf.co/spaces/alonsosilva/embeddings</a></p>
<div id="c77f0a15-bc2b-41f3-b435-0c3c8d3bbe53" class="cell" data-execution_count="32">
<div class="cell-output cell-output-display" data-execution_count="32">

        <iframe width="850" height="450" src="https://alonsosilva-embeddings.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="presente-de-los-llms-2" class="slide level2">
<h2>Presente de los LLMs</h2>
<p>Chatbots</p>
<p>Generación Aumentada con Recuperación (RAG)</p>
<p>Etiquetado</p>
<div class="fragment semi-fade-out">
<p>Extracción</p>
<p>Agentes</p>
</div>
</section>
<section id="etiquetado" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb35-2"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb35-3"><a href=""></a></span>
<span id="cb35-4"><a href=""></a><span class="kw">class</span> Etiquetaje(BaseModel):</span>
<span id="cb35-5"><a href=""></a>    <span class="co">"""Etiqueta el fragmento de texto con la información particular."""</span></span>
<span id="cb35-6"><a href=""></a>    sentimiento: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"sentimiento del texto, debe ser `positivo`, `negativo`, o `neutral`"</span>)</span>
<span id="cb35-7"><a href=""></a>    lenguaje: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"lenguaje del texto (debe ser código ISO 639-1)"</span>)</span>
<span id="cb35-8"><a href=""></a></span>
<span id="cb35-9"><a href=""></a>tagging_function <span class="op">=</span> [convert_pydantic_to_openai_function(Etiquetaje)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-1" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb36" data-code-line-numbers="1,4-7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb36-2"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb36-3"><a href=""></a></span>
<span id="cb36-4"><a href=""></a><span class="kw">class</span> Etiquetaje(BaseModel):</span>
<span id="cb36-5"><a href=""></a>    <span class="co">"""Etiqueta el fragmento de texto con la información particular."""</span></span>
<span id="cb36-6"><a href=""></a>    sentimiento: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"sentimiento del texto, debe ser `positivo`, `negativo`, o `neutral`"</span>)</span>
<span id="cb36-7"><a href=""></a>    lenguaje: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"lenguaje del texto (debe ser código ISO 639-1)"</span>)</span>
<span id="cb36-8"><a href=""></a></span>
<span id="cb36-9"><a href=""></a>tagging_function <span class="op">=</span> [convert_pydantic_to_openai_function(Etiquetaje)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-2" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb37" data-code-line-numbers="2,9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb37-2"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb37-3"><a href=""></a></span>
<span id="cb37-4"><a href=""></a><span class="kw">class</span> Etiquetaje(BaseModel):</span>
<span id="cb37-5"><a href=""></a>    <span class="co">"""Etiqueta el fragmento de texto con la información particular."""</span></span>
<span id="cb37-6"><a href=""></a>    sentimiento: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"sentimiento del texto, debe ser `positivo`, `negativo`, o `neutral`"</span>)</span>
<span id="cb37-7"><a href=""></a>    lenguaje: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"lenguaje del texto (debe ser código ISO 639-1)"</span>)</span>
<span id="cb37-8"><a href=""></a></span>
<span id="cb37-9"><a href=""></a>tagging_function <span class="op">=</span> [convert_pydantic_to_openai_function(Etiquetaje)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-3" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb38-2"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb38-3"><a href=""></a></span>
<span id="cb38-4"><a href=""></a><span class="kw">class</span> Etiquetaje(BaseModel):</span>
<span id="cb38-5"><a href=""></a>    <span class="co">"""Etiqueta el fragmento de texto con la información particular."""</span></span>
<span id="cb38-6"><a href=""></a>    sentimiento: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"sentimiento del texto, debe ser `positivo`, `negativo`, o `neutral`"</span>)</span>
<span id="cb38-7"><a href=""></a>    lenguaje: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"lenguaje del texto (debe ser código ISO 639-1)"</span>)</span>
<span id="cb38-8"><a href=""></a></span>
<span id="cb38-9"><a href=""></a>tagging_function <span class="op">=</span> [convert_pydantic_to_openai_function(Etiquetaje)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-4" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb39-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb39-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb39-4"><a href=""></a></span>
<span id="cb39-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb39-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb39-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb39-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb39-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb39-11"><a href=""></a>])</span>
<span id="cb39-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb39-13"><a href=""></a></span>
<span id="cb39-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"No me gusta esta comida"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-5" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb40" data-code-line-numbers="12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb40-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb40-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb40-4"><a href=""></a></span>
<span id="cb40-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb40-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb40-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb40-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb40-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb40-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb40-11"><a href=""></a>])</span>
<span id="cb40-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb40-13"><a href=""></a></span>
<span id="cb40-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"No me gusta esta comida"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-6" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb41" data-code-line-numbers="1,5-6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb41-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb41-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb41-4"><a href=""></a></span>
<span id="cb41-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb41-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb41-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb41-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb41-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb41-11"><a href=""></a>])</span>
<span id="cb41-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb41-13"><a href=""></a></span>
<span id="cb41-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"No me gusta esta comida"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-7" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb42" data-code-line-numbers="2,7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb42-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb42-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb42-4"><a href=""></a></span>
<span id="cb42-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb42-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb42-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb42-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb42-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb42-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb42-11"><a href=""></a>])</span>
<span id="cb42-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb42-13"><a href=""></a></span>
<span id="cb42-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"No me gusta esta comida"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-8" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb43" data-code-line-numbers="3,8-11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb43-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb43-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb43-4"><a href=""></a></span>
<span id="cb43-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb43-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb43-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb43-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb43-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb43-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb43-11"><a href=""></a>])</span>
<span id="cb43-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb43-13"><a href=""></a></span>
<span id="cb43-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"No me gusta esta comida"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-9" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb44" data-code-line-numbers="14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb44-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb44-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb44-4"><a href=""></a></span>
<span id="cb44-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb44-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb44-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb44-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb44-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb44-11"><a href=""></a>])</span>
<span id="cb44-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb44-13"><a href=""></a></span>
<span id="cb44-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"No me gusta esta comida"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-10" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb45-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb45-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb45-4"><a href=""></a></span>
<span id="cb45-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb45-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb45-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb45-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb45-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb45-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb45-11"><a href=""></a>])</span>
<span id="cb45-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb45-13"><a href=""></a></span>
<span id="cb45-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"No me gusta esta comida"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="f9850b9c-7dab-46b4-8687-5349d4cae5e7" class="cell" data-execution_count="65">
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>{'sentimiento': 'negativo', 'lenguaje': 'es'}</code></pre>
</div>
</div>
</section>
<section id="etiquetado-11" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb47" data-code-line-numbers="14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb47-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb47-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb47-4"><a href=""></a></span>
<span id="cb47-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb47-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb47-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb47-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb47-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb47-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb47-11"><a href=""></a>])</span>
<span id="cb47-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb47-13"><a href=""></a></span>
<span id="cb47-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"I love Nokia"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="etiquetado-12" class="slide level2">
<h2>Etiquetado</h2>
<div class="sourceCode" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb48-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonOutputFunctionsParser</span>
<span id="cb48-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb48-4"><a href=""></a></span>
<span id="cb48-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb48-6"><a href=""></a>model_with_functions <span class="op">=</span> model.bind(functions<span class="op">=</span>tagging_function, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Etiquetaje"</span>})</span>
<span id="cb48-7"><a href=""></a>output_parser <span class="op">=</span> JsonOutputFunctionsParser()</span>
<span id="cb48-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb48-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Piensa cuidadosamente, y luego etiqueta el texto como indicado"</span>),</span>
<span id="cb48-10"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb48-11"><a href=""></a>])</span>
<span id="cb48-12"><a href=""></a>tagging_chain <span class="op">=</span> prompt <span class="op">|</span> model_with_functions <span class="op">|</span> output_parser</span>
<span id="cb48-13"><a href=""></a></span>
<span id="cb48-14"><a href=""></a>tagging_chain.invoke({<span class="st">"input"</span>: <span class="st">"I love Nokia"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="a19e7f92-abb2-4bb5-b5fe-a20b32c6c771" class="cell" data-execution_count="66">
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>{'sentimiento': 'positivo', 'lenguaje': 'en'}</code></pre>
</div>
</div>
</section>
<section id="ejemplo-de-etiquetado" class="slide level2">
<h2>Ejemplo de etiquetado</h2>
<div id="008a1bce-b68e-4582-90f3-0e814c0dc70a" class="cell" data-execution_count="112">
<div class="cell-output cell-output-display" data-execution_count="112">

        <iframe width="700" height="550" src="https://tldres.streamlit.app/?embed=true" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="presente-de-los-llms-3" class="slide level2">
<h2>Presente de los LLMs</h2>
<p>Chatbots</p>
<p>Generación Aumentada con Recuperación (RAG)</p>
<p>Etiquetado</p>
<p>Extracción</p>
<div class="fragment semi-fade-out">
<p>Agentes</p>
</div>
</section>
<section id="extracción" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href=""></a><span class="im">from</span> typing <span class="im">import</span> List, Optional</span>
<span id="cb50-2"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb50-3"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb50-4"><a href=""></a></span>
<span id="cb50-5"><a href=""></a><span class="kw">class</span> Persona(BaseModel):</span>
<span id="cb50-6"><a href=""></a>    <span class="co">"""Información acerca de una persona."""</span></span>
<span id="cb50-7"><a href=""></a>    nombre: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"nombre de la persona"</span>)</span>
<span id="cb50-8"><a href=""></a>    edad: Optional[<span class="bu">int</span>] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"edad de la persona"</span>)</span>
<span id="cb50-9"><a href=""></a></span>
<span id="cb50-10"><a href=""></a><span class="kw">class</span> Informacion(BaseModel):</span>
<span id="cb50-11"><a href=""></a>    <span class="co">"""Información a extraer."""</span></span>
<span id="cb50-12"><a href=""></a>    people: List[Persona] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"Lista de información acerca de personas"</span>)</span>
<span id="cb50-13"><a href=""></a></span>
<span id="cb50-14"><a href=""></a>extraction_functions <span class="op">=</span> [convert_pydantic_to_openai_function(Informacion)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-1" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb51" data-code-line-numbers="1-2,5-8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href=""></a><span class="im">from</span> typing <span class="im">import</span> List, Optional</span>
<span id="cb51-2"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb51-3"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb51-4"><a href=""></a></span>
<span id="cb51-5"><a href=""></a><span class="kw">class</span> Persona(BaseModel):</span>
<span id="cb51-6"><a href=""></a>    <span class="co">"""Información acerca de una persona."""</span></span>
<span id="cb51-7"><a href=""></a>    nombre: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"nombre de la persona"</span>)</span>
<span id="cb51-8"><a href=""></a>    edad: Optional[<span class="bu">int</span>] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"edad de la persona"</span>)</span>
<span id="cb51-9"><a href=""></a></span>
<span id="cb51-10"><a href=""></a><span class="kw">class</span> Informacion(BaseModel):</span>
<span id="cb51-11"><a href=""></a>    <span class="co">"""Información a extraer."""</span></span>
<span id="cb51-12"><a href=""></a>    people: List[Persona] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"Lista de información acerca de personas"</span>)</span>
<span id="cb51-13"><a href=""></a></span>
<span id="cb51-14"><a href=""></a>extraction_functions <span class="op">=</span> [convert_pydantic_to_openai_function(Informacion)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-2" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb52" data-code-line-numbers="1-2,10-12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href=""></a><span class="im">from</span> typing <span class="im">import</span> List, Optional</span>
<span id="cb52-2"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb52-3"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb52-4"><a href=""></a></span>
<span id="cb52-5"><a href=""></a><span class="kw">class</span> Persona(BaseModel):</span>
<span id="cb52-6"><a href=""></a>    <span class="co">"""Información acerca de una persona."""</span></span>
<span id="cb52-7"><a href=""></a>    nombre: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"nombre de la persona"</span>)</span>
<span id="cb52-8"><a href=""></a>    edad: Optional[<span class="bu">int</span>] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"edad de la persona"</span>)</span>
<span id="cb52-9"><a href=""></a></span>
<span id="cb52-10"><a href=""></a><span class="kw">class</span> Informacion(BaseModel):</span>
<span id="cb52-11"><a href=""></a>    <span class="co">"""Información a extraer."""</span></span>
<span id="cb52-12"><a href=""></a>    people: List[Persona] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"Lista de información acerca de personas"</span>)</span>
<span id="cb52-13"><a href=""></a></span>
<span id="cb52-14"><a href=""></a>extraction_functions <span class="op">=</span> [convert_pydantic_to_openai_function(Informacion)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-3" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb53" data-code-line-numbers="3,14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href=""></a><span class="im">from</span> typing <span class="im">import</span> List, Optional</span>
<span id="cb53-2"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb53-3"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb53-4"><a href=""></a></span>
<span id="cb53-5"><a href=""></a><span class="kw">class</span> Persona(BaseModel):</span>
<span id="cb53-6"><a href=""></a>    <span class="co">"""Información acerca de una persona."""</span></span>
<span id="cb53-7"><a href=""></a>    nombre: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"nombre de la persona"</span>)</span>
<span id="cb53-8"><a href=""></a>    edad: Optional[<span class="bu">int</span>] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"edad de la persona"</span>)</span>
<span id="cb53-9"><a href=""></a></span>
<span id="cb53-10"><a href=""></a><span class="kw">class</span> Information(BaseModel):</span>
<span id="cb53-11"><a href=""></a>    <span class="co">"""Información a extraer."""</span></span>
<span id="cb53-12"><a href=""></a>    people: List[Persona] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"Lista de información acerca de personas"</span>)</span>
<span id="cb53-13"><a href=""></a></span>
<span id="cb53-14"><a href=""></a>extraction_functions <span class="op">=</span> [convert_pydantic_to_openai_function(Informacion)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-4" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href=""></a><span class="im">from</span> typing <span class="im">import</span> List, Optional</span>
<span id="cb54-2"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb54-3"><a href=""></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb54-4"><a href=""></a></span>
<span id="cb54-5"><a href=""></a><span class="kw">class</span> Persona(BaseModel):</span>
<span id="cb54-6"><a href=""></a>    <span class="co">"""Información acerca de una persona."""</span></span>
<span id="cb54-7"><a href=""></a>    nombre: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"nombre de la persona"</span>)</span>
<span id="cb54-8"><a href=""></a>    edad: Optional[<span class="bu">int</span>] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"edad de la persona"</span>)</span>
<span id="cb54-9"><a href=""></a></span>
<span id="cb54-10"><a href=""></a><span class="kw">class</span> Information(BaseModel):</span>
<span id="cb54-11"><a href=""></a>    <span class="co">"""Información a extraer."""</span></span>
<span id="cb54-12"><a href=""></a>    people: List[Persona] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"Lista de información acerca de personas"</span>)</span>
<span id="cb54-13"><a href=""></a></span>
<span id="cb54-14"><a href=""></a>extraction_functions <span class="op">=</span> [convert_pydantic_to_openai_function(Informacion)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-5" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb55-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonKeyOutputFunctionsParser</span>
<span id="cb55-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb55-4"><a href=""></a></span>
<span id="cb55-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb55-6"><a href=""></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Informacion"</span>})</span>
<span id="cb55-7"><a href=""></a>output_parser <span class="op">=</span> JsonKeyOutputFunctionsParser(key_name<span class="op">=</span><span class="st">"personas"</span>)</span>
<span id="cb55-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb55-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Extrae la información relevante, si no es dada explícitamente no adivines. Extrae información parcial"</span>),</span>
<span id="cb55-10"><a href=""></a>    (<span class="st">"human"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb55-11"><a href=""></a>])</span>
<span id="cb55-12"><a href=""></a></span>
<span id="cb55-13"><a href=""></a>extraction_chain <span class="op">=</span> prompt <span class="op">|</span> extraction_model <span class="op">|</span> output_parser</span>
<span id="cb55-14"><a href=""></a>extraction_chain.invoke({<span class="st">"input"</span>: <span class="st">"José tiene 30 años, su mamá es Marta, y su papá es Daniel que tiene 56"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-6" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb56" data-code-line-numbers="12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb56-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonKeyOutputFunctionsParser</span>
<span id="cb56-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb56-4"><a href=""></a></span>
<span id="cb56-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb56-6"><a href=""></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Informacion"</span>})</span>
<span id="cb56-7"><a href=""></a>output_parser <span class="op">=</span> JsonKeyOutputFunctionsParser(key_name<span class="op">=</span><span class="st">"personas"</span>)</span>
<span id="cb56-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb56-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Extrae la información relevante, si no es dada explícitamente no adivines. Extrae información parcial"</span>),</span>
<span id="cb56-10"><a href=""></a>    (<span class="st">"human"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb56-11"><a href=""></a>])</span>
<span id="cb56-12"><a href=""></a>extraction_chain <span class="op">=</span> prompt <span class="op">|</span> extraction_model <span class="op">|</span> output_parser</span>
<span id="cb56-13"><a href=""></a>extraction_chain.invoke({<span class="st">"input"</span>: <span class="st">"José tiene 30 años, su mamá es Marta, y su papá es Daniel que tiene 56"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-7" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb57" data-code-line-numbers="1,5-6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb57-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonKeyOutputFunctionsParser</span>
<span id="cb57-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb57-4"><a href=""></a></span>
<span id="cb57-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb57-6"><a href=""></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Informacion"</span>})</span>
<span id="cb57-7"><a href=""></a>output_parser <span class="op">=</span> JsonKeyOutputFunctionsParser(key_name<span class="op">=</span><span class="st">"personas"</span>)</span>
<span id="cb57-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb57-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Extrae la información relevante, si no es dada explícitamente no adivines. Extrae información parcial"</span>),</span>
<span id="cb57-10"><a href=""></a>    (<span class="st">"human"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb57-11"><a href=""></a>])</span>
<span id="cb57-12"><a href=""></a></span>
<span id="cb57-13"><a href=""></a>extraction_chain <span class="op">=</span> prompt <span class="op">|</span> extraction_model <span class="op">|</span> output_parser</span>
<span id="cb57-14"><a href=""></a>extraction_chain.invoke({<span class="st">"input"</span>: <span class="st">"José tiene 30 años, su mamá es Marta, y su papá es Daniel que tiene 56"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-8" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb58" data-code-line-numbers="2,7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb58-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonKeyOutputFunctionsParser</span>
<span id="cb58-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb58-4"><a href=""></a></span>
<span id="cb58-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb58-6"><a href=""></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Informacion"</span>})</span>
<span id="cb58-7"><a href=""></a>output_parser <span class="op">=</span> JsonKeyOutputFunctionsParser(key_name<span class="op">=</span><span class="st">"personas"</span>)</span>
<span id="cb58-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb58-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Extrae la información relevante, si no es dada explícitamente no adivines. Extrae información parcial"</span>),</span>
<span id="cb58-10"><a href=""></a>    (<span class="st">"human"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb58-11"><a href=""></a>])</span>
<span id="cb58-12"><a href=""></a></span>
<span id="cb58-13"><a href=""></a>extraction_chain <span class="op">=</span> prompt <span class="op">|</span> extraction_model <span class="op">|</span> output_parser</span>
<span id="cb58-14"><a href=""></a>extraction_chain.invoke({<span class="st">"input"</span>: <span class="st">"José tiene 30 años, su mamá es Marta, y su papá es Daniel que tiene 56"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-9" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb59" data-code-line-numbers="3,8-10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb59-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonKeyOutputFunctionsParser</span>
<span id="cb59-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb59-4"><a href=""></a></span>
<span id="cb59-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb59-6"><a href=""></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Informacion"</span>})</span>
<span id="cb59-7"><a href=""></a>output_parser <span class="op">=</span> JsonKeyOutputFunctionsParser(key_name<span class="op">=</span><span class="st">"personas"</span>)</span>
<span id="cb59-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb59-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Extrae la información relevante, si no es dada explícitamente no adivines. Extrae información parcial"</span>),</span>
<span id="cb59-10"><a href=""></a>    (<span class="st">"human"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb59-11"><a href=""></a>])</span>
<span id="cb59-12"><a href=""></a></span>
<span id="cb59-13"><a href=""></a>extraction_chain <span class="op">=</span> prompt <span class="op">|</span> extraction_model <span class="op">|</span> output_parser</span>
<span id="cb59-14"><a href=""></a>extraction_chain.invoke({<span class="st">"input"</span>: <span class="st">"José tiene 30 años, su mamá es Marta, y su papá es Daniel que tiene 56"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-10" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb60" data-code-line-numbers="14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb60-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonKeyOutputFunctionsParser</span>
<span id="cb60-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb60-4"><a href=""></a></span>
<span id="cb60-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb60-6"><a href=""></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Informacion"</span>})</span>
<span id="cb60-7"><a href=""></a>output_parser <span class="op">=</span> JsonKeyOutputFunctionsParser(key_name<span class="op">=</span><span class="st">"personas"</span>)</span>
<span id="cb60-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb60-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Extrae la información relevante, si no es dada explícitamente no adivines. Extrae información parcial"</span>),</span>
<span id="cb60-10"><a href=""></a>    (<span class="st">"human"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb60-11"><a href=""></a>])</span>
<span id="cb60-12"><a href=""></a></span>
<span id="cb60-13"><a href=""></a>extraction_chain <span class="op">=</span> prompt <span class="op">|</span> extraction_model <span class="op">|</span> output_parser</span>
<span id="cb60-14"><a href=""></a>extraction_chain.invoke({<span class="st">"input"</span>: <span class="st">"José tiene 30 años, su mamá es Marta, y su papá es Daniel que tiene 56"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracción-11" class="slide level2">
<h2>Extracción</h2>
<div class="sourceCode" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb61-2"><a href=""></a><span class="im">from</span> langchain.output_parsers.openai_functions <span class="im">import</span> JsonKeyOutputFunctionsParser</span>
<span id="cb61-3"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb61-4"><a href=""></a></span>
<span id="cb61-5"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb61-6"><a href=""></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>: <span class="st">"Informacion"</span>})</span>
<span id="cb61-7"><a href=""></a>output_parser <span class="op">=</span> JsonKeyOutputFunctionsParser(key_name<span class="op">=</span><span class="st">"personas"</span>)</span>
<span id="cb61-8"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb61-9"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Extrae la información relevante, si no es dada explícitamente no adivines. Extrae información parcial"</span>),</span>
<span id="cb61-10"><a href=""></a>    (<span class="st">"human"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>)</span>
<span id="cb61-11"><a href=""></a>])</span>
<span id="cb61-12"><a href=""></a></span>
<span id="cb61-13"><a href=""></a>extraction_chain <span class="op">=</span> prompt <span class="op">|</span> extraction_model <span class="op">|</span> output_parser</span>
<span id="cb61-14"><a href=""></a>extraction_chain.invoke({<span class="st">"input"</span>: <span class="st">"José tiene 30 años, su mamá es Marta, y su papá es Daniel que tiene 56"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="a3fb67ae-748e-466c-9915-0d5c1d99333c" class="cell" data-execution_count="75">
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>[{'nombre': 'José', 'edad': 30},
 {'nombre': 'Marta', 'edad': None},
 {'nombre': 'Daniel', 'edad': 56}]</code></pre>
</div>
</div>
</section>
<section id="presente-de-los-llms-4" class="slide level2">
<h2>Presente de los LLMs</h2>
<p>Chatbots</p>
<p>Generación Aumentada con Recuperación (RAG)</p>
<p>Etiquetado</p>
<p>Extracción</p>
<p>Agentes</p>
</section>
<section id="no-me-refiero-a-estos-agentes" class="slide level2">
<h2>No me refiero a estos agentes</h2>

<img data-src="PyCon2023_files/figure-revealjs/cell-30-output-1.jpeg" class="r-stretch"></section>
<section id="agentes" class="slide level2">
<h2>Agentes</h2>

<img data-src="PyCon2023_files/figure-revealjs/cell-31-output-1.jpeg" class="r-stretch"></section>
<section id="agentes-1" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb63-2"><a href=""></a><span class="im">from</span> langchain.tools <span class="im">import</span> tool</span>
<span id="cb63-3"><a href=""></a></span>
<span id="cb63-4"><a href=""></a><span class="kw">class</span> CalculateInput(BaseModel):</span>
<span id="cb63-5"><a href=""></a>    numexpr: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"La expresión numérica a ser evaluada"</span>)</span>
<span id="cb63-6"><a href=""></a>    </span>
<span id="cb63-7"><a href=""></a><span class="at">@tool</span>(args_schema<span class="op">=</span>CalculateInput)</span>
<span id="cb63-8"><a href=""></a><span class="kw">def</span> calculate(numexpr: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb63-9"><a href=""></a>    <span class="co">"""Calcula la expresión numérica"""</span></span>
<span id="cb63-10"><a href=""></a>    <span class="cf">return</span> <span class="bu">eval</span>(numexpr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-2" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb64" data-code-line-numbers="1,4-5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb64-2"><a href=""></a><span class="im">from</span> langchain.tools <span class="im">import</span> tool</span>
<span id="cb64-3"><a href=""></a></span>
<span id="cb64-4"><a href=""></a><span class="kw">class</span> CalculateInput(BaseModel):</span>
<span id="cb64-5"><a href=""></a>    numexpr: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"La expresión numérica a ser evaluada"</span>)</span>
<span id="cb64-6"><a href=""></a>    </span>
<span id="cb64-7"><a href=""></a><span class="at">@tool</span>(args_schema<span class="op">=</span>CalculateInput)</span>
<span id="cb64-8"><a href=""></a><span class="kw">def</span> calculate(numexpr: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb64-9"><a href=""></a>    <span class="co">"""Calcula la expresión numérica"""</span></span>
<span id="cb64-10"><a href=""></a>    <span class="cf">return</span> <span class="bu">eval</span>(numexpr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-3" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb65" data-code-line-numbers="2,7-10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb65-2"><a href=""></a><span class="im">from</span> langchain.tools <span class="im">import</span> tool</span>
<span id="cb65-3"><a href=""></a></span>
<span id="cb65-4"><a href=""></a><span class="kw">class</span> CalculateInput(BaseModel):</span>
<span id="cb65-5"><a href=""></a>    numexpr: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"La expresión numérica a ser evaluada"</span>)</span>
<span id="cb65-6"><a href=""></a>    </span>
<span id="cb65-7"><a href=""></a><span class="at">@tool</span>(args_schema<span class="op">=</span>CalculateInput)</span>
<span id="cb65-8"><a href=""></a><span class="kw">def</span> calculate(numexpr: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb65-9"><a href=""></a>    <span class="co">"""Calcula la expresión numérica"""</span></span>
<span id="cb65-10"><a href=""></a>    <span class="cf">return</span> <span class="bu">eval</span>(numexpr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-4" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href=""></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb66-2"><a href=""></a><span class="im">from</span> langchain.tools <span class="im">import</span> tool</span>
<span id="cb66-3"><a href=""></a></span>
<span id="cb66-4"><a href=""></a><span class="kw">class</span> CalculateInput(BaseModel):</span>
<span id="cb66-5"><a href=""></a>    numexpr: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"La expresión numérica a ser evaluada"</span>)</span>
<span id="cb66-6"><a href=""></a>    </span>
<span id="cb66-7"><a href=""></a><span class="at">@tool</span>(args_schema<span class="op">=</span>CalculateInput)</span>
<span id="cb66-8"><a href=""></a><span class="kw">def</span> calculate(numexpr: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb66-9"><a href=""></a>    <span class="co">"""Calcula la expresión numérica"""</span></span>
<span id="cb66-10"><a href=""></a>    <span class="cf">return</span> <span class="bu">eval</span>(numexpr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-5" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href=""></a><span class="im">import</span> wikipedia</span>
<span id="cb67-2"><a href=""></a>wikipedia.set_lang(<span class="st">"es"</span>)</span>
<span id="cb67-3"><a href=""></a></span>
<span id="cb67-4"><a href=""></a><span class="kw">class</span> SearchWikipediaInput(BaseModel):</span>
<span id="cb67-5"><a href=""></a>    query: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"Lo que se busca"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-6" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb68"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href=""></a><span class="at">@tool</span>(args_schema<span class="op">=</span>SearchWikipediaInput)</span>
<span id="cb68-2"><a href=""></a><span class="kw">def</span> search_wikipedia(query: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb68-3"><a href=""></a>    <span class="co">"""Busca en Wikipedia y obtiene resúmenes de distintas páginas"""</span></span>
<span id="cb68-4"><a href=""></a>    page_titles <span class="op">=</span> wikipedia.search(query)</span>
<span id="cb68-5"><a href=""></a>    summaries <span class="op">=</span> []</span>
<span id="cb68-6"><a href=""></a>    <span class="cf">for</span> page_title <span class="kw">in</span> page_titles[: <span class="dv">3</span>]:</span>
<span id="cb68-7"><a href=""></a>        <span class="cf">try</span>:</span>
<span id="cb68-8"><a href=""></a>            wiki_page <span class="op">=</span>  wikipedia.page(title<span class="op">=</span>page_title, auto_suggest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb68-9"><a href=""></a>            summaries.append(<span class="ss">f"Page: </span><span class="sc">{</span>page_title<span class="sc">}</span><span class="ch">\n</span><span class="ss">Summary: </span><span class="sc">{</span>wiki_page<span class="sc">.</span>summary<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb68-10"><a href=""></a>        <span class="cf">except</span> (</span>
<span id="cb68-11"><a href=""></a>            <span class="va">self</span>.wiki_client.exceptions.PageError,</span>
<span id="cb68-12"><a href=""></a>            <span class="va">self</span>.wiki_client.exceptions.DisambiguationError,</span>
<span id="cb68-13"><a href=""></a>        ):</span>
<span id="cb68-14"><a href=""></a>            <span class="cf">pass</span></span>
<span id="cb68-15"><a href=""></a>    <span class="cf">if</span> <span class="kw">not</span> summaries:</span>
<span id="cb68-16"><a href=""></a>        <span class="cf">return</span> <span class="st">"No se encontró ningún buen resultado al buscar en Wikipedia"</span></span>
<span id="cb68-17"><a href=""></a>    <span class="cf">return</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>.join(summaries)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-7" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href=""></a><span class="im">from</span> langchain.tools.render <span class="im">import</span> format_tool_to_openai_function</span>
<span id="cb69-2"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb69-3"><a href=""></a><span class="im">from</span> langchain.agents.output_parsers <span class="im">import</span> OpenAIFunctionsAgentOutputParser</span>
<span id="cb69-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb69-5"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> MessagesPlaceholder</span>
<span id="cb69-6"><a href=""></a>tools <span class="op">=</span> [calculate, search_wikipedia]</span>
<span id="cb69-7"><a href=""></a>functions <span class="op">=</span> [format_tool_to_openai_function(tool) <span class="cf">for</span> tool <span class="kw">in</span> tools]</span>
<span id="cb69-8"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>functions)</span>
<span id="cb69-9"><a href=""></a>output_parser <span class="op">=</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb69-10"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb69-11"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil"</span>),</span>
<span id="cb69-12"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb69-13"><a href=""></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb69-14"><a href=""></a>])</span>
<span id="cb69-15"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-8" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb70" data-code-line-numbers="15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href=""></a><span class="im">from</span> langchain.tools.render <span class="im">import</span> format_tool_to_openai_function</span>
<span id="cb70-2"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb70-3"><a href=""></a><span class="im">from</span> langchain.agents.output_parsers <span class="im">import</span> OpenAIFunctionsAgentOutputParser</span>
<span id="cb70-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb70-5"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> MessagesPlaceholder</span>
<span id="cb70-6"><a href=""></a>tools <span class="op">=</span> [calculate, search_wikipedia]</span>
<span id="cb70-7"><a href=""></a>functions <span class="op">=</span> [format_tool_to_openai_function(tool) <span class="cf">for</span> tool <span class="kw">in</span> tools]</span>
<span id="cb70-8"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>functions)</span>
<span id="cb70-9"><a href=""></a>output_parser <span class="op">=</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb70-10"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb70-11"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil"</span>),</span>
<span id="cb70-12"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb70-13"><a href=""></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb70-14"><a href=""></a>])</span>
<span id="cb70-15"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-9" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb71" data-code-line-numbers="1,6-7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href=""></a><span class="im">from</span> langchain.tools.render <span class="im">import</span> format_tool_to_openai_function</span>
<span id="cb71-2"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb71-3"><a href=""></a><span class="im">from</span> langchain.agents.output_parsers <span class="im">import</span> OpenAIFunctionsAgentOutputParser</span>
<span id="cb71-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb71-5"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> MessagesPlaceholder</span>
<span id="cb71-6"><a href=""></a>tools <span class="op">=</span> [calculate, search_wikipedia]</span>
<span id="cb71-7"><a href=""></a>functions <span class="op">=</span> [format_tool_to_openai_function(tool) <span class="cf">for</span> tool <span class="kw">in</span> tools]</span>
<span id="cb71-8"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>functions)</span>
<span id="cb71-9"><a href=""></a>output_parser <span class="op">=</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb71-10"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb71-11"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil"</span>),</span>
<span id="cb71-12"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb71-13"><a href=""></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb71-14"><a href=""></a>])</span>
<span id="cb71-15"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-10" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb72" data-code-line-numbers="2,8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href=""></a><span class="im">from</span> langchain.tools.render <span class="im">import</span> format_tool_to_openai_function</span>
<span id="cb72-2"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb72-3"><a href=""></a><span class="im">from</span> langchain.agents.output_parsers <span class="im">import</span> OpenAIFunctionsAgentOutputParser</span>
<span id="cb72-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb72-5"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> MessagesPlaceholder</span>
<span id="cb72-6"><a href=""></a>tools <span class="op">=</span> [calculate, search_wikipedia]</span>
<span id="cb72-7"><a href=""></a>functions <span class="op">=</span> [format_tool_to_openai_function(tool) <span class="cf">for</span> tool <span class="kw">in</span> tools]</span>
<span id="cb72-8"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>functions)</span>
<span id="cb72-9"><a href=""></a>output_parser <span class="op">=</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb72-10"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb72-11"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil"</span>),</span>
<span id="cb72-12"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb72-13"><a href=""></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb72-14"><a href=""></a>])</span>
<span id="cb72-15"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-11" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb73" data-code-line-numbers="3,9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href=""></a><span class="im">from</span> langchain.tools.render <span class="im">import</span> format_tool_to_openai_function</span>
<span id="cb73-2"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb73-3"><a href=""></a><span class="im">from</span> langchain.agents.output_parsers <span class="im">import</span> OpenAIFunctionsAgentOutputParser</span>
<span id="cb73-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb73-5"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> MessagesPlaceholder</span>
<span id="cb73-6"><a href=""></a>tools <span class="op">=</span> [calculate, search_wikipedia]</span>
<span id="cb73-7"><a href=""></a>functions <span class="op">=</span> [format_tool_to_openai_function(tool) <span class="cf">for</span> tool <span class="kw">in</span> tools]</span>
<span id="cb73-8"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>functions)</span>
<span id="cb73-9"><a href=""></a>output_parser <span class="op">=</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb73-10"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb73-11"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil"</span>),</span>
<span id="cb73-12"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb73-13"><a href=""></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb73-14"><a href=""></a>])</span>
<span id="cb73-15"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-12" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb74" data-code-line-numbers="4-5,10-14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href=""></a><span class="im">from</span> langchain.tools.render <span class="im">import</span> format_tool_to_openai_function</span>
<span id="cb74-2"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb74-3"><a href=""></a><span class="im">from</span> langchain.agents.output_parsers <span class="im">import</span> OpenAIFunctionsAgentOutputParser</span>
<span id="cb74-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb74-5"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> MessagesPlaceholder</span>
<span id="cb74-6"><a href=""></a>tools <span class="op">=</span> [calculate, search_wikipedia]</span>
<span id="cb74-7"><a href=""></a>functions <span class="op">=</span> [format_tool_to_openai_function(tool) <span class="cf">for</span> tool <span class="kw">in</span> tools]</span>
<span id="cb74-8"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>functions)</span>
<span id="cb74-9"><a href=""></a>output_parser <span class="op">=</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb74-10"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb74-11"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil"</span>),</span>
<span id="cb74-12"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb74-13"><a href=""></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb74-14"><a href=""></a>])</span>
<span id="cb74-15"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-13" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href=""></a><span class="im">from</span> langchain.tools.render <span class="im">import</span> format_tool_to_openai_function</span>
<span id="cb75-2"><a href=""></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb75-3"><a href=""></a><span class="im">from</span> langchain.agents.output_parsers <span class="im">import</span> OpenAIFunctionsAgentOutputParser</span>
<span id="cb75-4"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb75-5"><a href=""></a><span class="im">from</span> langchain.prompts <span class="im">import</span> MessagesPlaceholder</span>
<span id="cb75-6"><a href=""></a>tools <span class="op">=</span> [calculate, search_wikipedia]</span>
<span id="cb75-7"><a href=""></a>functions <span class="op">=</span> [format_tool_to_openai_function(tool) <span class="cf">for</span> tool <span class="kw">in</span> tools]</span>
<span id="cb75-8"><a href=""></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>functions)</span>
<span id="cb75-9"><a href=""></a>output_parser <span class="op">=</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb75-10"><a href=""></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb75-11"><a href=""></a>    (<span class="st">"system"</span>, <span class="st">"Eres un asistente útil"</span>),</span>
<span id="cb75-12"><a href=""></a>    (<span class="st">"user"</span>, <span class="st">"Responde como una persona soberbia y condescendiente a la siguiente pregunta: </span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb75-13"><a href=""></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb75-14"><a href=""></a>])</span>
<span id="cb75-15"><a href=""></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-14" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb76"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href=""></a><span class="im">from</span> langchain.agents.format_scratchpad <span class="im">import</span> format_to_openai_functions</span>
<span id="cb76-2"><a href=""></a><span class="im">from</span> langchain.schema.agent <span class="im">import</span> AgentFinish</span>
<span id="cb76-3"><a href=""></a><span class="kw">def</span> run_agent(user_input):</span>
<span id="cb76-4"><a href=""></a>    intermediate_steps <span class="op">=</span> []</span>
<span id="cb76-5"><a href=""></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb76-6"><a href=""></a>        result <span class="op">=</span> chain.invoke({</span>
<span id="cb76-7"><a href=""></a>            <span class="st">"input"</span>: user_input, </span>
<span id="cb76-8"><a href=""></a>            <span class="st">"agent_scratchpad"</span>: format_to_openai_functions(intermediate_steps)</span>
<span id="cb76-9"><a href=""></a>        })</span>
<span id="cb76-10"><a href=""></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(result, AgentFinish):</span>
<span id="cb76-11"><a href=""></a>            <span class="cf">return</span> result</span>
<span id="cb76-12"><a href=""></a>        tool <span class="op">=</span> {</span>
<span id="cb76-13"><a href=""></a>            <span class="st">"search_wikipedia"</span>: search_wikipedia, </span>
<span id="cb76-14"><a href=""></a>            <span class="st">"calculate"</span>: calculate,</span>
<span id="cb76-15"><a href=""></a>        }[result.tool]</span>
<span id="cb76-16"><a href=""></a>        observation <span class="op">=</span> tool.run(result.tool_input)</span>
<span id="cb76-17"><a href=""></a>        intermediate_steps.append((result, observation))</span>
<span id="cb76-18"><a href=""></a>result <span class="op">=</span> run_agent(<span class="st">"¿Quién es Gabriel Boric?"</span>)</span>
<span id="cb76-19"><a href=""></a>result.return_values[<span class="st">'output'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="agentes-15" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb77"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href=""></a><span class="im">from</span> langchain.agents.format_scratchpad <span class="im">import</span> format_to_openai_functions</span>
<span id="cb77-2"><a href=""></a><span class="im">from</span> langchain.schema.agent <span class="im">import</span> AgentFinish</span>
<span id="cb77-3"><a href=""></a><span class="kw">def</span> run_agent(user_input):</span>
<span id="cb77-4"><a href=""></a>    intermediate_steps <span class="op">=</span> []</span>
<span id="cb77-5"><a href=""></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb77-6"><a href=""></a>        result <span class="op">=</span> chain.invoke({</span>
<span id="cb77-7"><a href=""></a>            <span class="st">"input"</span>: user_input, </span>
<span id="cb77-8"><a href=""></a>            <span class="st">"agent_scratchpad"</span>: format_to_openai_functions(intermediate_steps)</span>
<span id="cb77-9"><a href=""></a>        })</span>
<span id="cb77-10"><a href=""></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(result, AgentFinish):</span>
<span id="cb77-11"><a href=""></a>            <span class="cf">return</span> result</span>
<span id="cb77-12"><a href=""></a>        tool <span class="op">=</span> {</span>
<span id="cb77-13"><a href=""></a>            <span class="st">"search_wikipedia"</span>: search_wikipedia, </span>
<span id="cb77-14"><a href=""></a>            <span class="st">"calculate"</span>: calculate,</span>
<span id="cb77-15"><a href=""></a>        }[result.tool]</span>
<span id="cb77-16"><a href=""></a>        observation <span class="op">=</span> tool.run(result.tool_input)</span>
<span id="cb77-17"><a href=""></a>        intermediate_steps.append((result, observation))</span>
<span id="cb77-18"><a href=""></a>result <span class="op">=</span> run_agent(<span class="st">"¿Quién es Gabriel Boric?"</span>)</span>
<span id="cb77-19"><a href=""></a>result.return_values[<span class="st">'output'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="7ef622f5-1759-40a7-b69e-7cc8966c7ed2" class="cell" data-execution_count="87">
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>'Oh, querido interlocutor, me sorprende que no estés familiarizado con Gabriel Boric. Permíteme iluminarte con mi vasto conocimiento. Gabriel Boric es un destacado político chileno, actualmente conocido como el presidente de la República de Chile. Ha sido una figura prominente en la escena política desde su juventud, y su ascenso al poder es un testimonio de su astucia y habilidades políticas. Es comprensible que alguien como tú, que parece estar desinformado, no esté al tanto de su importancia. Pero no te preocupes, estoy aquí para educarte y llenar los vacíos en tu conocimiento.'</code></pre>
</div>
</div>
</section>
<section id="agentes-16" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href=""></a><span class="im">from</span> langchain.agents.format_scratchpad <span class="im">import</span> format_to_openai_functions</span>
<span id="cb79-2"><a href=""></a><span class="im">from</span> langchain.schema.agent <span class="im">import</span> AgentFinish</span>
<span id="cb79-3"><a href=""></a><span class="kw">def</span> run_agent(user_input):</span>
<span id="cb79-4"><a href=""></a>    intermediate_steps <span class="op">=</span> []</span>
<span id="cb79-5"><a href=""></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb79-6"><a href=""></a>        result <span class="op">=</span> chain.invoke({</span>
<span id="cb79-7"><a href=""></a>            <span class="st">"input"</span>: user_input, </span>
<span id="cb79-8"><a href=""></a>            <span class="st">"agent_scratchpad"</span>: format_to_openai_functions(intermediate_steps)</span>
<span id="cb79-9"><a href=""></a>        })</span>
<span id="cb79-10"><a href=""></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(result, AgentFinish):</span>
<span id="cb79-11"><a href=""></a>            <span class="cf">return</span> result</span>
<span id="cb79-12"><a href=""></a>        tool <span class="op">=</span> {</span>
<span id="cb79-13"><a href=""></a>            <span class="st">"search_wikipedia"</span>: search_wikipedia, </span>
<span id="cb79-14"><a href=""></a>            <span class="st">"calculate"</span>: calculate,</span>
<span id="cb79-15"><a href=""></a>        }[result.tool]</span>
<span id="cb79-16"><a href=""></a>        observation <span class="op">=</span> tool.run(result.tool_input)</span>
<span id="cb79-17"><a href=""></a>        intermediate_steps.append((result, observation))</span>
<span id="cb79-18"><a href=""></a>result <span class="op">=</span> run_agent(<span class="st">"¿Cuánto es 23456 por 54321?"</span>)</span>
<span id="cb79-19"><a href=""></a>result.return_values[<span class="st">'output'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="2db7781a-6a67-4b6d-a730-b0786ca6a4a1" class="cell" data-execution_count="93">
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>'Oh, querido interlocutor, es evidente que no tienes la capacidad de realizar cálculos tan simples como este. Permíteme iluminarte con mi vasto conocimiento. El resultado de multiplicar 23456 por 54321 es 1,274,153,376. Ahora, ¿hay algo más en lo que pueda ayudarte?'</code></pre>
</div>
</div>
</section>
<section id="agentes-17" class="slide level2">
<h2>Agentes</h2>
<div class="sourceCode" id="cb81"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href=""></a><span class="im">from</span> langchain.agents.format_scratchpad <span class="im">import</span> format_to_openai_functions</span>
<span id="cb81-2"><a href=""></a><span class="im">from</span> langchain.schema.agent <span class="im">import</span> AgentFinish</span>
<span id="cb81-3"><a href=""></a><span class="kw">def</span> run_agent(user_input):</span>
<span id="cb81-4"><a href=""></a>    intermediate_steps <span class="op">=</span> []</span>
<span id="cb81-5"><a href=""></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb81-6"><a href=""></a>        result <span class="op">=</span> chain.invoke({</span>
<span id="cb81-7"><a href=""></a>            <span class="st">"input"</span>: user_input, </span>
<span id="cb81-8"><a href=""></a>            <span class="st">"agent_scratchpad"</span>: format_to_openai_functions(intermediate_steps)</span>
<span id="cb81-9"><a href=""></a>        })</span>
<span id="cb81-10"><a href=""></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(result, AgentFinish):</span>
<span id="cb81-11"><a href=""></a>            <span class="cf">return</span> result</span>
<span id="cb81-12"><a href=""></a>        tool <span class="op">=</span> {</span>
<span id="cb81-13"><a href=""></a>            <span class="st">"search_wikipedia"</span>: search_wikipedia, </span>
<span id="cb81-14"><a href=""></a>            <span class="st">"calculate"</span>: calculate,</span>
<span id="cb81-15"><a href=""></a>        }[result.tool]</span>
<span id="cb81-16"><a href=""></a>        observation <span class="op">=</span> tool.run(result.tool_input)</span>
<span id="cb81-17"><a href=""></a>        intermediate_steps.append((result, observation))</span>
<span id="cb81-18"><a href=""></a>result <span class="op">=</span> run_agent(<span class="st">"¡Hola!"</span>)</span>
<span id="cb81-19"><a href=""></a>result.return_values[<span class="st">'output'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="c7059d5b-5fdd-410d-be7c-4995206616d4" class="cell" data-execution_count="94">
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>'Oh, hola. ¿Necesitas algo o simplemente querías saludar a alguien tan impresionante como yo?'</code></pre>
</div>
</div>
</section>
<section id="ejemplo-de-agente" class="slide level2">
<h2>Ejemplo de agente</h2>
<p><a href="https://math-solver.streamlit.app/">https://math-solver.streamlit.app/</a></p>
<div id="a9373519-4b0a-4ec0-8cf3-cf75d32f8a3c" class="cell" data-execution_count="110">
<div class="cell-output cell-output-display" data-execution_count="110">

        <iframe width="700" height="550" src="https://math-solver.streamlit.app/?embed=true" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="ejemplo-de-agente-1" class="slide level2">
<h2>Ejemplo de agente</h2>
<p><a href="https://asilva.streamlit.app/">https://asilva.streamlit.app/</a></p>
<p>Let’s think step by step. Tell me about the livestock population in Turkey. Make a bar plot with these quantities.</p>
<div id="d42abd04-e807-4b4e-99cc-aa1fea7e9109" class="cell" data-execution_count="111">
<div class="cell-output cell-output-display" data-execution_count="111">

        <iframe width="700" height="550" src="https://asilva.streamlit.app/?embed=true" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="ejemplo-de-agente-2" class="slide level2">
<h2>Ejemplo de agente</h2>

<img data-src="PyCon2023_files/figure-revealjs/cell-40-output-1.jpeg" class="r-stretch"></section>
<section id="tabla-de-contenidos-1" class="slide level2">
<h2>Tabla de contenidos</h2>
<p>Presente de los LLMs</p>
<p>Órganos internos de los LLMs</p>
<div class="fragment semi-fade-out">
<p>Conclusiones y perspectivas</p>
</div>
</section>
<section id="tokenizer" class="slide level2">
<h2>Tokenizer</h2>
<p><a href="https://hf.co/spaces/alonsosilva/tokenizer">https://hf.co/spaces/alonsosilva/tokenizer</a></p>
<div id="ce8077fb-6592-4d04-b3fc-349a17e73904" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display" data-execution_count="6">

        <iframe width="850" height="450" src="https://alonsosilva-tokenizer.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="picogpt" class="slide level2">
<h2>PicoGPT</h2>
<p><a href="https://picogpt.streamlit.app/">https://picogpt.streamlit.app/</a></p>
<div id="0e248b1d-077a-498b-9d4b-26404bb6856c" class="cell" data-execution_count="21">
<div class="cell-output cell-output-display" data-execution_count="21">

        <iframe width="700" height="550" src="https://picogpt.streamlit.app/?embed=true" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="next-token-prediction" class="slide level2">
<h2>Next token prediction</h2>
<p><a href="https://hf.co/spaces/alonsosilva/NextTokenPrediction">https://hf.co/spaces/alonsosilva/NextTokenPrediction</a></p>
<div id="57334baa" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display" data-execution_count="5">

        <iframe width="700" height="700" src="https://alonsosilva-nexttokenprediction.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="gpt-2" class="slide level2">
<h2>GPT-2</h2>
<p><a href="https://hf.co/spaces/alonsosilva/gpt2">https://hf.co/spaces/alonsosilva/gpt2</a></p>
<div id="9f5e90d3-640f-4c3e-86bd-84f5283a8bdb" class="cell" data-execution_count="13">
<div class="cell-output cell-output-display" data-execution_count="13">

        <iframe width="850" height="450" src="https://alonsosilva-gpt2.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="attention-shapley-values" class="slide level2">
<h2>Attention: Shapley values</h2>
<p><a href="https://shapllm.streamlit.app/">https://shapllm.streamlit.app/</a></p>
<div id="08f71170-b714-4efd-ad90-875502b5c15f" class="cell" data-execution_count="27">
<div class="cell-output cell-output-display" data-execution_count="27">

        <iframe width="850" height="550" src="https://shapllm.streamlit.app/?embed=True" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="attention-tracing" class="slide level2">
<h2>Attention Tracing</h2>
<p><a href="https://github.com/mattneary/attention">https://github.com/mattneary/attention</a></p>

<img src="./assets/Attention.gif" width="750" align="center" class="r-stretch"></section>
<section id="tabla-de-contenidos-2" class="slide level2">
<h2>Tabla de contenidos</h2>
<p>Presente de los LLMs</p>
<p>Órganos internos de los LLMs</p>
<p>Conclusiones y perspectivas</p>
</section>
<section id="conclusiones-y-perspectivas" class="slide level2">
<h2>Conclusiones y Perspectivas</h2>
<ul>
<li>LLMs tienen una gran cantidad de aplicaciones:
<ul>
<li>Chatbots</li>
<li>Generación aumentada con recuperación</li>
<li>Etiquetaje</li>
<li>Extracción</li>
<li>Agentes</li>
</ul></li>
<li>LLMs actuales son autoregresivos, predicen sólo el próximo token y están dotados de un mecanismo de atención</li>
</ul>
</section>
<section id="conclusiones-y-perspectivas-1" class="slide level2">
<h2>Conclusiones y Perspectivas</h2>
<ul>
<li>No sabemos qué nuevas aplicaciones vendrán en el futuro</li>
</ul>

<img data-src="PyCon2023_files/figure-revealjs/cell-48-output-1.jpeg" class="r-stretch"></section>
<section id="muchas-gracias-por-su-atención" class="slide level2">
<h2>Muchas gracias por su atención</h2>
<p>Presentación: <a href="https://github.com/alonsosilvaallende/PyCon_Chile_2023">https://github.com/alonsosilvaallende/PyCon_Chile_2023</a></p>
<p>Contáctame:</p>
<ul>
<li>Twitter: <a href="https://twitter.com/alonsosilva"><span class="citation" data-cites="alonsosilva">@alonsosilva</span></a></li>
<li>GitHub: <a href="https://github.com/alonsosilvaallende/"><span class="citation" data-cites="alonsosilvaallende">@alonsosilvaallende</span></a></li>
<li>Correo: <a href="mailto:alonso.silva@gmail.com">alonso.silva@gmail.com</a></li>
</ul>
</section>
<section id="appendix" class="slide level2">
<h2>Appendix</h2>
</section>
<section id="perplexity" class="slide level2">
<h2>Perplexity</h2>
<p><a href="https://hf.co/spaces/alonsosilva/perplexity">https://hf.co/spaces/alonsosilva/perplexity</a></p>
<div id="8cc4b226-61ba-4a69-92c6-4ce429ae62c8" class="cell" data-execution_count="22">
<div class="cell-output cell-output-display" data-execution_count="22">

        <iframe width="850" height="450" src="https://alonsosilva-perplexity.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
<section id="appendix-1" class="slide level2">
<h2>Appendix</h2>


<img data-src="PyCon2023_files/figure-revealjs/cell-50-output-1.jpeg" class="r-stretch"></section>
    <div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div></div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="PyCon2023_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="PyCon2023_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="PyCon2023_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="PyCon2023_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="PyCon2023_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="PyCon2023_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="PyCon2023_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="PyCon2023_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="PyCon2023_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="PyCon2023_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>